{
  "hash": "cabca9d48fea83676b0e3f2714907bf9",
  "result": {
    "markdown": "---\ntitle: \"Analyzing every minutes of my spare time in R: 6 months of time tracking insights\"\ncategories: [life, R, data, viz, dplyr, 2023]\ndescription: \"What does the time tell me?\"\ndate: 2023-09-18\nformat: \n  html:\n    df-print: kable\nimage: devt_0824_1.png\n---\n\n\nI've always believed that how I spend my spare time will have an impact on my future. Based on this philosophy, I started tracking my spare time, which includes any time outside of sleep hours and my 9-5 work schedule. I now have over 6 months' worth of data, and here are my findings I've done with R.\n\n## Time tracking category\n\nTo get started, I came up with 6 main categories.\n\n- **Essentials**: This includes activities like eating, showering, doing chores and grocery shopping\n- **Sanity**: Things that aren't essential but are important for maintaining my sanity, including reading articles, trying out new apps, and engaging in quality leisure activities e.g. playing video games\n- **Professional development**: Skill development that would bring direct benefit to my professional career\n- **Personal development**: Hobbies or skills that are not related to my career. They are skills that hold long-term value to me, such as knitting, blogging and website tweaking\n- **Wellness**: Mental and physical well-being activities, such as talking to my husband/cats and strength training\n- **Distraction**: \"Zombie mode\". Mindless scrolling on social media, or idle time when I'm not doing anything particularly useful\n\n## Data preparation\n\nMy data is partially synced to Google Calendar (see [Apps I used for time tracking](#apps-i-used-for-time-tracking) for more details),  with each event representing an activity. I exported all calendars as .ics files, converted them to csv utilizing the `ics2csv` library, and then used `bind_rows` to combine them with my other csv files.\n\nSince I don't publish the data, I won't delve into all the details of data cleaning and aggregation, as they aren't reproducible. However, here are a few things I considered:\n\n- There were a few days I didn't have complete data because I switched the tool. These need to be excluded to get an accurate daily average.\n- I also changed the granularity of the category in the middle by adding more sub-categories. To ensure consistency, I rolled these sub-categories to the their parent categories, so that all categories are reported at the same level. A useful function here is `case_match`, which is suitable to map multiple values to the same output.\n- To aggregate the data, I counted the hours of each category on each day by  `group_by` and `summarize`, and then reshaped the data using `pivot_wider`.\n- I separated the data into two data frames by weekday and weekend , because I obviously have more spare time on the weekend, and I don't want this variance to be spread out if I were to do a daily average\n\nAfter the preparation, I have two data frame: `hrs_weekday` and `hrs_weekend`, which contain the breakdown of each category on weekdays and weekends, respectively. The structure of data frames looks like below.\n\n\n::: {.cell}\n::: {.cell-output-display}\n<div class=\"kable-table\">\n\n|dtdate     | Distraction| Essentials|    Sanity|  Wellness|   PersDev|ProfDev |\n|:----------|-----------:|----------:|---------:|---------:|---------:|:-------|\n|2023-02-10 |   0.6322222|   6.285278| 1.5500000| 0.7836111|        NA|NA      |\n|2023-02-13 |   0.6616667|   5.285278| 0.5566667|        NA| 2.3925000|NA      |\n|2023-02-14 |   1.0436111|   6.801389| 0.6250000| 0.6636111| 0.7350000|NA      |\n|2023-02-15 |   0.6611111|   3.718056| 1.2347222|        NA| 2.8708333|NA      |\n|2023-02-16 |   1.9377778|   5.551667| 0.5000000| 1.9127778| 0.7752778|NA      |\n|2023-02-17 |   1.3572222|   3.295278| 1.2613889| 0.4233333| 1.7458333|NA      |\n\n</div>\n:::\n:::\n\n\nEach column is a category, and each row represents the daily sum of the corresponding category on a given day. \n\nIn addition, I created a constant `midpoint`, which is the midpoint of all date. This will help formatting the labels later when plotting time series graphs.\n\n## Where did my time go?\n\nAfter excluding sleep and work hours, my activity breakdown looked like this in a pie chart.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Click to show the code\"}\n# Import library ----\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(ggTimeSeries)\nlibrary(ggrepel)\nlibrary(grid)\nlibrary(gridExtra)\n\n# Define colour palette ----\n\ncustom_colors <- c(\"Essentials\" = \"#F2E1C9\", \"PersDev\" = \"#ADD4CD\", \"ProfDev\" = \"#b6dcf5\", \"Distraction\" = \"#FDBAA0\", \"Sanity\" = \"#D1D9EA\", \"Wellness\" = \"#DBEFBA\")\n\n# By activity ----\n\n## Prep ----\n\n# Reshape the data and calculate total/avg/percentage spent of each category\nget_main_cat <- function(df) {\n  df %>%\n    pivot_longer(!dtdate, names_to = \"main_cat\", values_to = \"daily_spent\") %>%\n    group_by(main_cat) %>%\n    summarize(\n      total_spent = sum(daily_spent, na.rm = TRUE),\n      avg_spent = total_spent / n_distinct(.$dtdate)\n    ) %>%\n    mutate(\n      pct_spent = total_spent / sum(total_spent),\n      # Get the positions for plotting pie chart\n      # Source: https://r-charts.com/part-whole/pie-chart-labels-outside-ggplot2/\n      csum = rev(cumsum(rev(avg_spent))),\n      pos = avg_spent / 2 + lead(csum, 1),\n      pos = if_else(is.na(pos), avg_spent / 2, pos)\n    )\n}\n\ncat_weekday <- get_main_cat(hrs_weekday)\ncat_weekend <- get_main_cat(hrs_weekend)\n\n## Plot category ----\n\n# Plot pie chart\nplot_main_cat <- function(df, p_title) {\n  ggplot(df, aes(x = \"\", y = avg_spent, fill = main_cat)) +\n    # Plot the pie of main_cat\n    geom_bar(stat = \"identity\", width = 1, color = \"white\") +\n    coord_polar(theta = \"y\", start = 0) +\n    # Add daily avg label for pie chart\n    geom_label_repel(\n      aes(y = pos, label = paste(main_cat, \"\\n\", round(avg_spent, 2), \"h\")),\n      colour = \"black\",\n      seed = 0,\n      force = 0.6,\n      segment.colour = NA,\n      show.legend = NA\n    ) +\n    # Add percentage\n    geom_text(aes(x = 1.6, y = pos, label = paste0(round(pct_spent * 100), \"%\")),\n      fontface = \"bold\"\n    ) +\n    theme_void() +\n    scale_fill_manual(values = custom_colors) +\n    labs(\n      subtitle = p_title,\n      caption = paste(\"Total =\", round(sum(df$avg_spent), 1), \"hours\"),\n    ) +\n    theme(\n      plot.subtitle = element_text(hjust = 0.5, vjust = -3),\n      legend.position = \"none\",\n      plot.caption = element_text(hjust = 0, vjust = 30, size = 11) # Set caption to left align\n    )\n}\n\np_cat_weekday <- plot_main_cat(cat_weekday, \"Weekday\")\np_cat_weekend <- plot_main_cat(cat_weekend, \"Weekend\")\n\ntitle <- textGrob(\"How I spent my spare time\", gp = gpar(fontsize = 16, font = 2)) %>%\n  arrangeGrob(zeroGrob(),\n    widths = unit(0, \"npc\"),\n    heights = unit(c(1, 0), c(\"cm\", \"npc\")),\n    as.table = FALSE\n  )\n\ncap <- textGrob(\"*Exclude sleep and work hours\", gp = gpar(fontsize = 10, font = 3)) %>%\n  arrangeGrob(zeroGrob(),\n    widths = unit(0, \"npc\"),\n    heights = unit(c(0, 10), c(\"cm\", \"npc\")),\n    as.table = FALSE\n  )\np_cat <- grid.arrange(p_cat_weekday, p_cat_weekend,\n  ncol = 2,\n  top = title, bottom = cap\n)\n```\n:::\n\n\n![How I spent my spare time by activity category](main_cat_0914_9.png)\n\nOn an average weekday, I have a total of **10.1 hours** available after excluding Sleep and Work hours. On the weekend, I have **14.4 hours**.\n\nThe biggest category is **Essentials**. I spent an average of **~5 hours** each day on life essential activities, which may seem like a lot, but it really isn't, considering non-routine chores such as grocery shopping.\n\n**Sanity** (**2-3 hours**) also took up a significant portion on both weekdays and weekends. These activities are, in a way, also essential to me because they are necessary to keep my sanity in check.\n\n**Personal development** is the one that shows the most variance; I spent **1.77 hours more** on it during the weekend. This makes sense, since I have more free time to invest in my hobbies on the weekends.\n\nI'm glad to find out that **Distraction** wasn't as bad as I thought. I spent roughly **40 minutes** on mindless scrolling on the weekday, and a bit more on the weekend.\n\nThe pie chart is probably the most tricky one, because it has two sets of labels — daily average and percentage — and I need to ensure that both labels align with the corresponding portions. Due to this reason, it's necessary to [get the position](https://r-charts.com/part-whole/pie-chart-labels-outside-ggplot2/) before creating the graph and applying them to y in `aes()`. After plotting the pie chart for weekdays and weekends, I use `gridExtra::grid.arrange()` to combine two pies, and  `grid::textGrob()` to format the title and captions.\n\n## How much time is necessary to keep life going?\n\nBy my definition, **Essentials** include both activities to keep the body alive, as well as house chores. These are the times I cannot cut.\n\nSo, how much time is necessary to keep my body alive and my life going? The answer is **4.98 hours** on weekdays, and **5.14 hours** on weekends.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Click to show the code\"}\n# Essentials and free time ----\n\n## Prep ----\n# Spare hours: everything exclude work hours and sleep time\n# Devt hours: personal devt + professional devt\n# Free hours: spare hours that are not in Essentials cat\n\nget_essentials_wk <- function(df) {\n  df %>% \n    mutate(spare_hr = rowSums(across(where(is.numeric)), na.rm = TRUE), # Sum all spare hours\n           devt_hr = rowSums(across(c(PersDev, ProfDev)), na.rm = TRUE)) %>% # Calculate the total hours of skill development\n    mutate(free_hr = rowSums(across(-c(Essentials, spare_hr, dtdate, devt_hr)), na.rm = TRUE)) %>% # Calculate the free hour = spare hours - essentials\n    group_by(week = week(dtdate)) %>% \n    mutate(wk_spare = mean(spare_hr),\n           wk_essentials = mean(Essentials),\n           wk_free = mean(free_hr)) %>% \n    ungroup()\n}\n\nessentials_weekday <- get_essentials_wk(hrs_weekday)\nessentials_weekend <- get_essentials_wk(hrs_weekend)\n\n## Plot Essentials ----\n\nplot_essentials <- function(df, p_title) {\n  avg_essentials <- mean(df$Essentials) # Calculate the average essentials hours\n  ggplot(df) +\n    # Plot essentials by day\n    geom_point(\n               aes(x = dtdate, y = Essentials), \n               color = \"#eed8b9\", \n               size = 1) +\n    # Plot essentials by week\n    geom_line(\n              aes(x = dtdate, y = wk_essentials),\n              color = \"#e3bf8b\", linewidth = 1) +\n    # Add mean trend line\n    geom_hline(\n      yintercept = avg_essentials, color = \"#766e53\", linetype = \"dotted\",\n      linewidth = 0.7\n    ) +\n    labs(x = \"\", y = \"Hours\", title = p_title) +\n    scale_x_date(date_breaks = \"1 month\", date_labels = \"%b\") +\n    scale_y_continuous(limits = c(0, 15)) + # set the y axis limit to 15 hours\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5, vjust = 1.5, size = 15),\n      plot.margin = unit(c(0.5, 3, 0.5, 0.5), \"cm\"), # Set margin to allow space for annotation\n      panel.grid.major = element_blank(), # Remove grid lines\n      axis.title.y = element_text(size = 10)\n    ) +\n    annotate(\"text\",\n      x = max(df$dtdate) + 22, \n      y = avg_essentials,\n      label = paste(\"Avg Essentials\\n\", round(avg_essentials, 2), \"h\"),\n      color = \"black\", \n      size = 3.5\n    ) +\n    coord_cartesian(xlim = c(min(all_data$dtdate), max(all_data$dtdate)), clip = \"off\") # Set the x axis limit\n}\n\np_essentials_weekday <- plot_essentials(essentials_weekday, \"Essentials hours spent, weekday\")\np_essentials_weekend <- plot_essentials(essentials_weekend, \"Essentials hours spent, weekend\")\np_essentials <- grid.arrange(p_essentials_weekday, p_essentials_weekend, nrow = 2)\n```\n:::\n\n\n\n\n![How much time I spent on life essential activities](essentials_0915_3.png)\n\nThe brown line represents the weekly average, while the dots are the daily sum. I think a weekly average would be more meaningful to look at, because it balances out those non-daily essential activities and isn't as fluctuate as daily averages. \n\nOn the weekend graph, there was a peak in May, because I spent almost the entire day doing adulting chores on that weekend.\n\n## How much free time did I actually have?\n\nOne of the most important insights I want to gain from time tracking is to figure out how much time I actually have to do my own stuff. After excluding sleep, work and life essentials, I have **5.27 hours** on an average weekday and **9.32 hours** on an average weekend to enjoy my life.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Click to show the code\"}\n## Spare/free/essentials ----\n\nplot_spare_time <- function(df, p_title) {\n  avg_free <- mean(df$free_hr) # Calculate the average hours spent\n  ggplot(df, aes(x = dtdate)) +\n    geom_ribbon(aes(ymin = wk_spare, ymax = 24, fill = \"Sleep/Work\")) +\n    geom_ribbon(aes(ymin = 0, ymax = wk_spare, fill = \"Free\")) +\n    geom_ribbon(aes(ymin = 0, ymax = wk_essentials, fill = \"Essentials\")) +\n    scale_fill_manual(values = c(custom_colors, \"Sleep/Work\" = \"#F6F6F5\", \"Free\" = \"#C2DEDC\")) +\n    labs(title = p_title,\n         x = \"\",\n         y = \"Hours\") +\n    scale_x_date(date_labels = \"%b\", date_breaks = \"1 month\") +\n    theme_minimal() +\n    theme(\n      plot.title = element_text(hjust = 0.5, vjust = -1, size = 15),\n      axis.title.y = element_text(size = 10),\n      panel.grid.major = element_blank(), # Remove grid lines\n      panel.grid.minor = element_blank(),\n      legend.position = \"bottom\", \n      legend.title = element_blank()) +\n    geom_hline(yintercept = avg_free, color = \"#44867d\", linetype = \"dotted\",\n               linewidth = 0.7) +\n    annotate(\"text\", x = midpoint, y = avg_free,\n             label = paste(\"Avg Free =\", round(avg_free, 2), \"h\"),\n             color = \"black\", size = 4,\n             vjust = 1.5\n    )\n}\n\np_spare_weekday <- plot_spare_time(essentials_weekday, \"Available free time, weekday\")\np_spare_weekend <- plot_spare_time(essentials_weekend, \"Available free time, weekend\")\np_spare <- grid.arrange(p_spare_weekday, p_spare_weekend, nrow = 1)\n```\n:::\n\n\n\n![The time I was actually free vs Essentials](spare_0915_3.png)\n\nThe light green area represents the actual **Free** time I have, while the light brown is the **Essentials**, and the white area is **Sleep/Work** hours. These add up to 24 hours on the y-axis, so each area reflects the true portion of the entire time. Once again, the data is based on weekly average to avoid the over-fluctuation of daily averages.\n\n## Investing time in myself\n\nThe categories I use to evaluate my productivity are **Personal development** and **Profession development**. I decided to combine these two categories into a single one \"**Skill development**\",  knowing that the majority of it was contributed by the former, such as personal hobbies.\n\nOn an average weekday, I spent **1.77 hours** on skill development, while on weekends, I dedicate **3.72 hours** to it, which is almost 2 hours more in comparison. The significant variance (ranging from **0 to 9+ hours** per day) is interesting to look at, mostly because of my flow state style of doing tasks.\n\nOverall, not bad, I would say.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Click to show the code\"}\n# Skill development ----\n# Devt = PersDev + ProfDev hours\n\n## Prep ----\n# Combine weekday and weekend entry, and fill the blank with 0 to avoid grey area in graph\nhrs_all <- rbind(hrs_weekday, hrs_weekend) %>% \n  complete(dtdate = seq(min(dtdate), max(dtdate), by = \"day\"), \n           fill = list(devt_hr = 0))\n  \n# Calculate weekly average\ndevt_weekday_avg <- mean(hrs_weekday$devt_hr) %>% round(., 2)\ndevt_weekend_avg <- mean(hrs_weekend$devt_hr) %>% round(., 2)\n\n## Plot development hour chart in calendar heat map ----\np_devt <-\n  ggplot_calendar_heatmap(\n    hrs_all,\n    cDateColumnName = \"dtdate\",\n    cValueColumnName = \"devt_hr\",\n    dayBorderSize = 0.35,\n    dayBorderColour = \"grey\",\n    monthBorderSize = 0.35,\n    monthBorderColour = \"dimgrey\",\n    monthBorderLineEnd = \"round\"\n  ) +\n  xlab(NULL) +\n  ylab(NULL) +\n  scale_fill_continuous(low = \"white\", high = \"#45ccc7\") +\n  theme(\n    plot.title = element_text(hjust = 0.5, vjust = 1.5, size = 15, face = \"bold\"),\n    axis.title.y = element_text(size = 10),\n    axis.ticks = element_blank(), \n    legend.position = \"right\",\n    legend.title = element_blank(),\n    strip.background = element_blank(),\n    strip.text = element_blank(), # useful for only one year of data\n    plot.background = element_rect(color = \"white\"),\n    panel.border = element_blank(),\n    panel.background = element_blank(),\n    panel.grid = element_blank(),\n    plot.caption = element_text(hjust = 1, vjust = -5, size = 11)\n  ) +\n  labs(\n    title = \"Skill development\",\n    caption = paste(\"Weekday Avg =\", devt_weekday_avg, \"h\\n\",\n                    \"Weekend Avg =\", devt_weekend_avg, \"h\"))\n\np_devt\n```\n:::\n\n\n![Personal and professional development heat map](devt_0915_3.png)\n\nI chose heat map because I want to see how my productivity fluctuated as the season changed. To do this, I combined the weekdays and weekends data frame, filled in blank with zero, and then used `ggplot_calendar_heatmap()` in the `ggTimeSeries` library to plot the calendar heat map.\n\nMay seems to be the low point, mainly due to the peak in the Essentials graph when I'm busy at chores. April is also low, and I wanted to see what happened in April to cause that downfall. The natural assumption is that I was busy doing something else, but what is it? Let's find out.\n\n## Social media v.s others\n\nWhat happened in April? It had a peak in the **Sanity** category. After checking my monthly review, I remembered that I spent lots of time playing video games with my husband, and it was also the time when I bought Hogwarts Legacy, which I put **80 hours** into the game according to PS5 stats.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Click to show the code\"}\n# Dist/San/Devt ----\n\n## Prep ----\n\ndis_san_devt <- hrs_all %>% \n  group_by(month = month(dtdate)) %>% \n  summarize(Distraction = mean(Distraction, na.rm = TRUE),\n            Sanity = mean(Sanity, na.rm = TRUE),\n            Development = mean(devt_hr, na.rm = TRUE)) %>% \n  pivot_longer(!month, names_to = \"category\", values_to = \"mo_avg\")\n\n## Plot stacked bar chart for three categories of activity ----\np_dis_san_dev <- \n  ggplot(dis_san_devt, aes(fill = category, y = mo_avg, x = month)) +\n    scale_x_continuous(breaks = 1:12, labels = month.name) + # Set month labels\n    geom_bar(position = \"stack\", stat = \"identity\", width = 0.7) +\n    labs(x = \"\", y = \"Hours\", title = \"Distraction, Sanity and Development\") +\n    theme_minimal() +\n  # Set custom label for legend\n  scale_fill_manual(values = c(custom_colors, Development = \"#a2e5e3\"), \n                    labels = c('Skill Development', 'Distraction', 'Sanity')) +\n    theme(\n      plot.title = element_text(hjust = 0.5, vjust = 1.5, size = 15, face = \"bold\"),\n      plot.background = element_rect(color = \"white\"), \n      axis.title.y = element_text(size = 10),\n      legend.title = element_blank(),\n      legend.position = \"bottom\",\n      panel.grid = element_blank()\n    )\n\np_dis_san_dev\n```\n:::\n\n\n![Social media and others](dis_san_devt_0915_4.png)\n\nLooking at other month, there were ups and downs. I have a vague feeling that there might be a negative correlation between **Distraction** and **Skill development**, meaning that when I was spending more time on social media, I probably didn't have the mood to do anything productive.\n\n## Was I more productive when I spent less time on social media?\n\nThe answer is **No**. To my surprise, **Sanity** and **Skill development** were substitutes to each other. That means when I didn't want to spent time on developing my hobbies and skills, I tended to choose to entertain myself with activities like playing games instead of scrolling on social media.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Click to show the code\"}\n# Correlation Dist/Devt ----\n\n## Prep ----\n\ndis_devt <- hrs_all %>%\n  mutate(\n    # Convert NA to 0\n    Sanity = if_else(is.na(Sanity), 0, Sanity),\n    Distraction = if_else(is.na(Distraction), 0, Distraction)\n  )\n\n## Plot correlation ----\n\np_dis_devt <-\n  ggplot(dis_devt, aes(x = devt_hr, y = Distraction)) +\n  geom_point(aes(color = Sanity), size = 2) +\n  scale_colour_gradient(low = \"#D1D9EA\", high = \"darkorchid\") +\n  theme_classic() +\n  labs(x = \"Skill development\") +\n  geom_smooth(method = lm) +\n  theme(legend.position = \"bottom\")\n\np_dis_san <-\n  ggplot(dis_devt, aes(x = Sanity, y = Distraction)) +\n  geom_point(aes(color = devt_hr), size = 2) +\n  scale_colour_gradient(low = \"lightblue\", high = \"darkblue\", name = \"Skill development\") +\n  theme_classic() +\n  geom_smooth(method = lm) +\n\np_devt_san <-\n  ggplot(dis_devt, aes(y = Sanity, x = devt_hr)) +\n  geom_point(aes(color = Distraction), size = 2) +\n  scale_colour_gradient(low = \"gold\", high = \"red\") +\n  theme_classic() +\n  labs(x = \"Skill development\") +\n  geom_smooth(method = lm) +\n  theme(legend.position = \"bottom\")\n\n# Define common x and y axis limits\ncommon_limits <- coord_cartesian(\n  xlim = c(0, 10),\n  ylim = c(0, 10)\n)\n\n# Apply the common limits to each plot\np_dis_devt <- p_dis_devt + common_limits\np_dis_san <- p_dis_san + common_limits\np_devt_san <- p_devt_san + common_limits\n\np_cor <- grid.arrange(p_dis_devt, p_dis_san, p_devt_san, ncol = 3, widths = c(1, 1, 1))\n```\n:::\n\n\n\n\n![The relationship among Distraction, Sanity and Skill development](correlation_0918_1.png)\n\nIn the above chart, the three graphs show the relationship between **Distraction**, **Sanity** and **Skill development**. Each graph plots the relationship between two variables on the x and y using a scatter plot with a linear model, and the colour mapping of dots represents the third variable.\n\nFrom the first two graphs, I didn't see much correlation between **Distraction** and **Skill development**, nor **Distraction** and **Sanity**. The lines of linear model were almost flat. However, the third graph shows a correlation between **Sanity** and **Skill development**, making me draw the initial conclusion.\n\nAnother interesting fact is that my time spent on **Distraction** was relatively stable. As shown in all three graphs, **Distraction** ranged from **0 to 5 hours** per day, and the colour mapping in the third graph looks quite consistent with very little variance.\n\nScatter plots are not hard to create, but when arrange all three in the same view, `coord_cartesian()` is necessary in order to keep the axes at the same scale.\n\n## Bonus: more activities at a glimpse\n\n[I mentioned that I've changed the category in the middle](#data-preparation), because I realized that I need more details, especially for **Personal development** and **Profession development**, I want to know the exact time I spent on certain skills. For example, under **Personal development**, I created four sub-categories: Knitting, Blogging, Emacs and Website development.\n\nAfter some aggregation from raw data, I have a data frame `act` that looks like this.\n\n```R\n# A tibble: 12 × 3\n  activity   main_cat    total_spent\n  <chr>      <chr>             <dbl>\n1 Blogging   PersDev           22.2 \n2 CasReading Sanity            25.9 \n3 Coding     ProfDev           15.7 \n4 Emacs      PersDev           42.2 \n...\n```\n\nAnd this is the breakdown of the total time I spent on each sub-category, based on 2 months of data.\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Click to show the code\"}\np_activity <-\n  act %>%\n  # Make sure activity is sorted by category\n  arrange(main_cat) %>% # Sort by main_cat\n\t# This trick update the factor levels\n\t# Source: https://r-graph-gallery.com/267-reorder-a-variable-in-ggplot2.html\n  mutate(activity = factor(activity, levels = activity)) %>% \n  ggplot(aes(x = activity, y = total_spent)) +\n  # Plot bar line\n  geom_segment(aes(xend = activity, yend = 0), color = \"grey\") +\n  # Add lolipop that filled with main_cat color\n  geom_point(size = 4, aes(color = main_cat)) +\n  # Add labels\n  geom_text(aes(label = paste0(round(total_spent), \"h\")), hjust = -0.5) +\n  scale_color_manual(values = custom_colors,\n                     name = \"Category\") +\n  coord_flip(ylim = c(0, max(act$total_spent) + 20), clip = \"off\") +\n  theme_minimal() +\n  labs(x = \"Activity\", y = \"Hours\", title = \"How I spent my time, by sub-category\") +\n  theme(\n    plot.title = element_text(hjust = 0.5, vjust = 1.5, size = 16, face = \"bold\"),\n    panel.grid = element_blank(),\n    axis.title.y = element_text(size = 10),\n    plot.background = element_rect(color = \"white\")\n  )\n\np_activity\n```\n:::\n\n\n\n\n![How I spent my free time, by sub-category](activity_0918_1.png)\n\nEach lollipop shows the total amount of time I spent on a sub-category in my free time, and I coloured the lollipop to reflect the parent category as shown in the legend. I didn't go with daily or weekly average like previous graphs, because I only have 2 months of data and it's not representative enough to conduct a daily average analysis. For example, last month I spent an insane amount of time (**42 hours**) on learning Org-mode (**Emacs**), but this is not something I would do every day.\n\n**System maintenance** contributes a big portion to my free time. To clarify, it includes self-reflection reviews, tinkering with productivity systems, trying new apps, etc. I did spent a lot of time playing with some self-hosted apps recently, so it is entirely expected. Otherwise, I would reconsider the category and split it further.\n\nWhen plotting the lollipop graph, I reordered each sub-category to ensure they are arranged by their parent category. [There are many ways to do it](https://r-graph-gallery.com/267-reorder-a-variable-in-ggplot2.html), and I chose the `dplyr` way.\n\n## Apps I used for time tracking\n\nThe principle is simple. It needs to be easy and quick enough to track time. Anything that takes more than 10 seconds to track would not work for long period of time tracking.\n\n- [ATracker Pro](https://atracker.pro/home.html)\n\n  I used this app initially and switched to Time Golden later. It has the functionality to sync to Google Calendar as well as csv export with paid version.\n\n  It's easy to get started, and the UI looks polished. However, as I added more categories, it became difficult to quickly locate the category as it doesn't have the parent-children layer. It also has the same drawback like many other tracking apps — I often forgot to start a task when I began doing something, and only realized it halfway through.\n\n- [Time Golden](http://www.timegolden.com)\n\n  The philosophy of this app is quite unique. The user needs to tap only **after** finishing an activity, not before. This is because the app is based on 24/7 non-stop time tracking, which means any time that has passed has to be assigned to a category. Therefore, there are no more \"blanks\" when tracking time.\n\n  This makes a huge difference. Because 24/7 tracking means I can no longer lie to myself. If I can control when to start and end tracking, I tend not to record unproductive time and thus cheat the report. With non-stop tracking, I have to assign the unproductive time to something else if I were to cheat, which creates a psychological barrier against such behaviours.\n\n  The app has a relatively high learning curve, but after that, I found it's extremely easy to track time because I can easily remember to tap it after I've done something.\n\n  I synced each category to a Google Calendar and then exported my data from there. I recently bought the paid version, which allows csv export.\n\n  \n\n---\n\n**Time I spent on this article**\n\n- Data prep: 2h11m\n- Data analysis and visualization: 35h23m\n- Article content: 8h42m\n- Polish for publishing: 3h45m\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}